{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae711e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wolfe_search(f, df, x, p, alpha0, c1, c2):\n",
    "    \"\"\"\n",
    "    Implements the Wolfe line-search algorithm (Algorithm 8) which returns a\n",
    "    step length fulfilling the strong Wolfe conditions.\n",
    "\n",
    "    Arguments:\n",
    "        f      : objective function f(x)\n",
    "        df     : gradient function df(x)\n",
    "        x      : current iterate\n",
    "        p      : search direction\n",
    "        alpha0 : initial upper bracket / step-length guess\n",
    "        c1, c2 : Wolfe condition parameters (0 < c1 < c2 < 1)\n",
    "\n",
    "    Returns:\n",
    "        alpha    : step length satisfying the strong Wolfe conditions\n",
    "        brackets : list of [l, u] brackets recorded at each iteration\n",
    "    \"\"\"\n",
    "    # Scalar wrappers: g(a) = f(x + a*p),  g'(a) = ∇f(x+a*p)ᵀp\n",
    "    def g(a):\n",
    "        return f(x + a * p)\n",
    "\n",
    "    def dg(a):\n",
    "        return np.inner(df(x + a * p), p)\n",
    "\n",
    "    l = 0\n",
    "    u = alpha0\n",
    "    brackets = [[l, u]]   # record initial bracket (iteration 1)\n",
    "\n",
    "    # ── Phase 1: expansion ────────────────────────────────────────────\n",
    "    while True:\n",
    "        if g(u) > g(0) + c1 * u * dg(0) or g(u) > g(l):\n",
    "            break\n",
    "        if abs(dg(u)) < c2 * abs(dg(0)):\n",
    "            return u, brackets\n",
    "        if dg(u) > 0:\n",
    "            break\n",
    "        else:\n",
    "            u = u * 2\n",
    "            brackets.append([l, u])\n",
    "\n",
    "    # ── Phase 2: bisection ────────────────────────────────────────────\n",
    "    while True:\n",
    "        brackets.append([l, u])\n",
    "        a = (l + u) / 2\n",
    "        if g(a) > g(0) + c1 * a * dg(0) or g(a) > g(l):\n",
    "            u = a\n",
    "        else:\n",
    "            if abs(dg(a)) < c2 * abs(dg(0)):\n",
    "                return a, brackets\n",
    "            if dg(a) < 0:\n",
    "                l = a\n",
    "            else:\n",
    "                u = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169d2ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfgs(f, df, x0, c1, c2, tol=1e-6, max_iter=1000):\n",
    "    \"\"\"\n",
    "    Implements the BFGS Quasi-Newton algorithm (Algorithm 9) using\n",
    "    wolfe_search (Algorithm 8) for the line search.\n",
    "\n",
    "    Arguments:\n",
    "        f        : objective function f(x)\n",
    "        df       : gradient function df(x)\n",
    "        x0       : initial iterate\n",
    "        c1, c2   : Wolfe condition parameters (0 < c1 < c2 < 1)\n",
    "        tol      : stopping tolerance on gradient norm\n",
    "        max_iter : maximum number of iterations\n",
    "\n",
    "    Returns:\n",
    "        x        : estimate of local minimum\n",
    "        iterates : list of iterates [x_0, x_1, ..., x_{k+1}]\n",
    "    \"\"\"\n",
    "    n = len(x0)\n",
    "    H = np.eye(n)          # H_0 = I_n\n",
    "    x = x0.copy()\n",
    "    iterates = [x.copy()]\n",
    "\n",
    "    for k in range(max_iter):\n",
    "        grad = df(x)\n",
    "\n",
    "        # Stopping condition\n",
    "        if np.linalg.norm(grad) < tol:\n",
    "            break\n",
    "\n",
    "        # p_k = -H_k ∇f(x_k)\n",
    "        p = -H @ grad\n",
    "\n",
    "        # α_k = wolfe_search(x_k, p_k, 1.0, c1, c2)\n",
    "        alpha, _ = wolfe_search(f, df, x, p, 1.0, c1, c2)\n",
    "\n",
    "        # x_{k+1} = x_k + α_k p_k\n",
    "        x_new = x + alpha * p\n",
    "\n",
    "        # y_k = ∇f(x_{k+1}) - ∇f(x_k)\n",
    "        y = df(x_new) - grad\n",
    "\n",
    "        # s_k = α_k p_k\n",
    "        s = alpha * p\n",
    "\n",
    "        # BFGS update of H\n",
    "        sy = s @ y                          # s_k^T y_k  (scalar)\n",
    "        Hy = H @ y                          # H_k y_k\n",
    "\n",
    "        H = (H\n",
    "             + ((sy + y @ Hy) / sy**2) * np.outer(s, s)\n",
    "             - (np.outer(Hy, s) + np.outer(s, Hy)) / sy)\n",
    "\n",
    "        x = x_new\n",
    "        iterates.append(x.copy())\n",
    "\n",
    "    return x, iterates\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numerical-optimization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
